---
layout: post
title: "Lessons from the Enova Data Smackdown"
date: 2014-01-11 02:54:29
categories: data_science
---

Analytics sometimes feels like a lonely pursuit. People work on different problems, making it difficult to figure out how much better you could be doing on yours. 

At the Enova Data Smackdown, we were given four hours, a modest dataset, and tasked with determining which customers Enova should spend money marketing to in order to maximize profits. For <a href='http://nelsonauner.com'>Nelson Auner</a> and me, it was a valuable opportunity to study other approaches to the same problem. We ended up winning, but more importantly, these are, in my opinion, the three biggest reasons why we won.

1. Two Stage Model
===============
We used a two stage model to predict customer profitability: The first stage predicted which customers would respond to marketing. The second, how much revenue customers who responded would generate. 

A single stage model wrongly interprets non-responding customers as generating zero revenue when in fact, they could be highly profitable or unprofitable had they responded. None of the other finalist seemed to have realized this.

2. Classification not Regression
=============================
Take a look at the distribution <img src='/pics/enova_graph.jpg' width='50%' style='float: right; margin-left: 1em;'>of customer profitability from the training set.

Isn't this surprising? Profitability isn't normally distributed! Customers are either highly profitable or unprofitable*. All of a sudden, it's no longer important to find out exactly how profitable a customer is. Merely realizing a customer is profitable is good enough. This turns the problem from a regression problem into a classification problem. 

We thus ran a logistics regression and, to our surprise, the training error was .. zero. 

Granted, by splitting the problem up nicely, the two stage model opened the door to an easy solution to the second stage. Nevertheless, a regression technique would likely have performed more poorly as outliers would influence it too strongly.

3. Eyeballing Data
===============
Here's what we found by plotting various covariates against customer\_id:

<img src='/pics/enova_four.jpg' width='100%' style=''>

There are two distinct subsets in the data! 

Though we didn't have time to adapt our model based on this observation, I'm glad we discovered it. It showed the judges that we had studied the data, and, in hindsight, I would have been embarrassed to have missed a pattern this glaring.

Lessons Learnt
==============
1. __Concentrate on picking the right model class.__ Most likely, in smaller competitions like these, selecting an Adaboost classifier over KNN does little more than entice judges to quiz you about your choice of algorithm.

2. __Get your hands dirty early.__ Plot your data, eyeball it in a text editor. This'll help you catch the low hanging fruit and get a feel for the data.

3. __Don't rush to code.__ This results from following lessons 1 and 2. Nelson and I spent the first of the four hours planning. By then, everyone else was coding. However, we still ended up making most of our insights in the last 30 minutes while plotting graphs for the presentation. At that point, it was too late to exploit these insights. In hindsight, we should have put off coding and spent more time at the start exploring and planning. 

<br>

\* Turns out, the dataset wasn't harvested from Enova's database - it had been engineered for the competition. 